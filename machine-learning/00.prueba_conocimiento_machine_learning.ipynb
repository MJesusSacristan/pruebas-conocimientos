{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Prueba de Conocimiento: Machine Learning & NLP\n\nUsando el dataset de **`Tweets.csv`** y utilizando métodos de procesamiento de datos de **`NLP`**, desarrolla un modelo de predicción sobre la columna de **`sentiment`**.\n\n- Usa diferentes modelos de clasificación y compara sus métricas y el tiempo de ejecución de cada uno.\n- Retorna un **`DataFrame`** con los resultados (metricas) de todos los modelos.\n- Selecciona el mejor modelo y aplica **`GridSearch()`** para encontrar los mejores parámetros.\n- Usa algoritmos de **`PCA`** o de **`SMOTE`** si consideras que es necesario.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Expresiones regulares\nimport re\n\n# Procesado de textos\nimport nltk\n# nltk.download()\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\n\n# Modelo Bag-of-Word\nfrom sklearn.feature_extraction.text import CountVectorizer\n# Modelo TF-IDF\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Train, Test\nfrom sklearn.model_selection import train_test_split\n\n# Metricas\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n\n# Clasificadores\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import RadiusNeighborsClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Tiempo de ejecución\nimport time\n\n#GridSearchCV\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:36.589129Z","iopub.execute_input":"2022-05-03T21:53:36.589966Z","iopub.status.idle":"2022-05-03T21:53:38.517081Z","shell.execute_reply.started":"2022-05-03T21:53:36.589866Z","shell.execute_reply":"2022-05-03T21:53:38.515247Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tweets/Tweets.csv\")\n\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.518639Z","iopub.execute_input":"2022-05-03T21:53:38.518910Z","iopub.status.idle":"2022-05-03T21:53:38.692948Z","shell.execute_reply.started":"2022-05-03T21:53:38.518872Z","shell.execute_reply":"2022-05-03T21:53:38.692357Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.693957Z","iopub.execute_input":"2022-05-03T21:53:38.694636Z","iopub.status.idle":"2022-05-03T21:53:38.700663Z","shell.execute_reply.started":"2022-05-03T21:53:38.694603Z","shell.execute_reply":"2022-05-03T21:53:38.699704Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.702731Z","iopub.execute_input":"2022-05-03T21:53:38.703062Z","iopub.status.idle":"2022-05-03T21:53:38.743864Z","shell.execute_reply.started":"2022-05-03T21:53:38.703030Z","shell.execute_reply":"2022-05-03T21:53:38.742782Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"####################\n# Preprocesamiento #\n####################","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.745442Z","iopub.execute_input":"2022-05-03T21:53:38.745981Z","iopub.status.idle":"2022-05-03T21:53:38.750058Z","shell.execute_reply.started":"2022-05-03T21:53:38.745931Z","shell.execute_reply":"2022-05-03T21:53:38.749019Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Comprobar si hay NaN en alguna columna\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.751457Z","iopub.execute_input":"2022-05-03T21:53:38.752110Z","iopub.status.idle":"2022-05-03T21:53:38.780729Z","shell.execute_reply.started":"2022-05-03T21:53:38.752064Z","shell.execute_reply":"2022-05-03T21:53:38.779702Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Eliminar NaN: hay uno en la columna \"text\" y en la columna \"selected_text\"\ndf.dropna(inplace = True)\ndf.reset_index(drop = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.782020Z","iopub.execute_input":"2022-05-03T21:53:38.782689Z","iopub.status.idle":"2022-05-03T21:53:38.805599Z","shell.execute_reply.started":"2022-05-03T21:53:38.782640Z","shell.execute_reply":"2022-05-03T21:53:38.804900Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Eliminar la columna \"selected_text\", porque no es necesaria\ndf.drop([\"textID\", \"selected_text\"], axis = 1, inplace = True)\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.807542Z","iopub.execute_input":"2022-05-03T21:53:38.808080Z","iopub.status.idle":"2022-05-03T21:53:38.821597Z","shell.execute_reply.started":"2022-05-03T21:53:38.808036Z","shell.execute_reply":"2022-05-03T21:53:38.820535Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Pasar los valores de la columna \"sentiment\" a numéricos\ndf[\"sentiment\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.823220Z","iopub.execute_input":"2022-05-03T21:53:38.823841Z","iopub.status.idle":"2022-05-03T21:53:38.842264Z","shell.execute_reply.started":"2022-05-03T21:53:38.823778Z","shell.execute_reply":"2022-05-03T21:53:38.841386Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sent_dict = {valor : num for num, valor in enumerate(df[\"sentiment\"].unique())}\nsent_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.844997Z","iopub.execute_input":"2022-05-03T21:53:38.845231Z","iopub.status.idle":"2022-05-03T21:53:38.858240Z","shell.execute_reply.started":"2022-05-03T21:53:38.845203Z","shell.execute_reply":"2022-05-03T21:53:38.857301Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df[\"sentiment\"].replace(sent_dict, inplace = True)\ndf[\"sentiment\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.859389Z","iopub.execute_input":"2022-05-03T21:53:38.859649Z","iopub.status.idle":"2022-05-03T21:53:38.890876Z","shell.execute_reply.started":"2022-05-03T21:53:38.859610Z","shell.execute_reply":"2022-05-03T21:53:38.890297Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Preparación de stopwords en inglés\ndef preparar_stopwords():\n    # Cargar las stopwords de Inglés que vienen por defecto\n    stopwords = nltk.corpus.stopwords.words(\"english\")\n    \n    # Añadir palabras detectadas en la revisión a la lista de stopwords \n    stopwords.append(\"and\")\n    stopwords.append(\"http\")\n    stopwords.append(\"sooo\")\n    stopwords.append(\"soooo\")\n    \n    return stopwords","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.891823Z","iopub.execute_input":"2022-05-03T21:53:38.892354Z","iopub.status.idle":"2022-05-03T21:53:38.896898Z","shell.execute_reply.started":"2022-05-03T21:53:38.892323Z","shell.execute_reply":"2022-05-03T21:53:38.896001Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def limpiar_texto(lista, stopwords):\n    \n    # Lista para guardar los tokens del texto\n    tokens_texto = list()\n\n    # Recorrer la lista de textos\n    for texto in lista:\n        \n        # Lista vacía para recopilar los tokens limpios tras tratarlos\n        tokens_limpios = list()\n                \n        # Tokenizar el texto tras pasarlo a minúsculas y asignarles su tag\n        tokens = nltk.word_tokenize(text = texto.lower(), language = \"english\")\n        \n        for token in tokens:\n            # Si el token no está entre las stopwords, su longitud es mayor que 2 y no contiene dígitos ni apóstrofe\n            if ((token not in stopwords) and (len(token) > 2) and (re.findall(r\"[\\d]\", token) == []) and\n                not(token.startswith(\"*\")) and (re.findall(r\"`\", token) == []) and not(token.startswith(\"//\")) and\n                (re.findall(r\"[_]\", token) == []) and not(token.startswith(\".\")) and\n                (re.search(r\"\\b([a]{2})\\w*\", token) is None) and (re.search(r\"([b]{3})\\w*\", token) is None)):\n                # Es un token válido\n                tokens_limpios.append(token)\n \n        # Acumular la lista de tokens\n        tokens_texto.append(tokens_limpios)\n    \n    return tokens_texto","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.898476Z","iopub.execute_input":"2022-05-03T21:53:38.898858Z","iopub.status.idle":"2022-05-03T21:53:38.913213Z","shell.execute_reply.started":"2022-05-03T21:53:38.898712Z","shell.execute_reply":"2022-05-03T21:53:38.912233Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Obtener los tokens de cada fila\ndf[\"text_tokens\"] = limpiar_texto(df[\"text\"], preparar_stopwords())\n\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:38.914697Z","iopub.execute_input":"2022-05-03T21:53:38.915207Z","iopub.status.idle":"2022-05-03T21:53:48.697669Z","shell.execute_reply.started":"2022-05-03T21:53:38.915170Z","shell.execute_reply":"2022-05-03T21:53:48.696766Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Función para asociar pos a tag de un token para lematizarlo\ndef nltk_pos_tagger(nltk_tag):\n    if nltk_tag.startswith('J'):\n        return wordnet.ADJ\n    elif nltk_tag.startswith('V'):\n        return wordnet.VERB\n    elif nltk_tag.startswith('N'):\n        return wordnet.NOUN\n    elif nltk_tag.startswith('R'):\n        return wordnet.ADV\n    else:          \n        return None\n\n# Función para lematizar tokens\ndef lematizar_tokens(lista):\n    \n    # Lista para guardar los tokens lematizados\n    lem_texto = list()\n\n    # Inicializar el lematizador\n    lemmatizer = WordNetLemmatizer()\n    \n    # Recorrer la lista de listas de tokens\n    for num, tokens in enumerate(lista):\n\n        # Lista vacía para guardar la lematización de la lista de tokens\n        tokens_lem = list()\n\n        # Si hay tokens para lematizar\n        if len(tokens) > 0:\n\n            # Obtener el tag de los tokens de cada fila\n            tokens_tags = nltk.pos_tag(tokens)\n\n            # Por cada token y tag\n            for token, tag in tokens_tags:\n                # Obtener la pos asociada al tag\n                pos = nltk_pos_tagger(tag)\n                # Si el tag no tiene pos asociado\n                if pos is None:\n                    # Guardar el token\n                    tokens_lem.append(token)\n                else:        \n                    # Lematizar el token\n                    tokens_lem.append(lemmatizer.lemmatize(token, pos))\n\n        # Acumular la lista de lematización de tokens\n        lem_texto.append(\" \".join(tokens_lem))\n\n    return lem_texto","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:48.698920Z","iopub.execute_input":"2022-05-03T21:53:48.699208Z","iopub.status.idle":"2022-05-03T21:53:48.709680Z","shell.execute_reply.started":"2022-05-03T21:53:48.699179Z","shell.execute_reply":"2022-05-03T21:53:48.708830Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Lematizar los tokens de cada fila\ndf[\"text_tokens_lem\"] = lematizar_tokens(df[\"text_tokens\"])\n\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:53:48.711078Z","iopub.execute_input":"2022-05-03T21:53:48.711626Z","iopub.status.idle":"2022-05-03T21:54:09.718467Z","shell.execute_reply.started":"2022-05-03T21:53:48.711583Z","shell.execute_reply":"2022-05-03T21:54:09.716871Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:09.719960Z","iopub.execute_input":"2022-05-03T21:54:09.720227Z","iopub.status.idle":"2022-05-03T21:54:09.728561Z","shell.execute_reply.started":"2022-05-03T21:54:09.720198Z","shell.execute_reply":"2022-05-03T21:54:09.727640Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"############################################################\n# Preparar datos para aplicar los modelos de clasificación #\n############################################################","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:09.730777Z","iopub.execute_input":"2022-05-03T21:54:09.731855Z","iopub.status.idle":"2022-05-03T21:54:09.739544Z","shell.execute_reply.started":"2022-05-03T21:54:09.731764Z","shell.execute_reply":"2022-05-03T21:54:09.738589Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def feature_extraction(texto_lematizado):\n    \n    # Bag-of-Word\n    count_vectorizer = CountVectorizer()\n\n    frases = np.array(texto_lematizado)\n\n    # Entrenamos el modelo y transformamos los datos.\n    bag = count_vectorizer.fit_transform(frases)\n\n    # Obtener la lista de vocabulario que actúa como cabecera de las columnas\n    vocabulario_ordenado = sorted(count_vectorizer.vocabulary_, key = lambda x : count_vectorizer.vocabulary_[x])\n    \n    # TF-IDF\n\n    # Inicializamos un objeto Tfidf\n    tfidf = TfidfTransformer()\n\n    # Cambio la precisión de python a 2 decimales\n    np.set_printoptions(precision = 2)\n\n    # Entrenamos el Tfidf y transformamos la variable bag\n    bag = tfidf.fit_transform(bag).toarray()\n\n    bag = pd.DataFrame(data = bag, columns = vocabulario_ordenado)\n\n    return bag","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:09.741137Z","iopub.execute_input":"2022-05-03T21:54:09.741886Z","iopub.status.idle":"2022-05-03T21:54:09.752415Z","shell.execute_reply.started":"2022-05-03T21:54:09.741832Z","shell.execute_reply":"2022-05-03T21:54:09.751753Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"bag = feature_extraction(df[\"text_tokens_lem\"])\nbag.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:09.753927Z","iopub.execute_input":"2022-05-03T21:54:09.754674Z","iopub.status.idle":"2022-05-03T21:54:11.101684Z","shell.execute_reply.started":"2022-05-03T21:54:09.754618Z","shell.execute_reply":"2022-05-03T21:54:11.100698Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(bag, df[\"sentiment\"], test_size = 0.3, random_state = 42)\n\nprint(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\nprint(f\"X_test: {X_test.shape},  y_test: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:11.102723Z","iopub.execute_input":"2022-05-03T21:54:11.102988Z","iopub.status.idle":"2022-05-03T21:54:13.922162Z","shell.execute_reply.started":"2022-05-03T21:54:11.102960Z","shell.execute_reply":"2022-05-03T21:54:13.921215Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#################################################################################################\n# Ejecutar diferentes modelos de clasificación y comparar sus métricas y el tiempo de ejecución #\n#################################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:13.923319Z","iopub.execute_input":"2022-05-03T21:54:13.923554Z","iopub.status.idle":"2022-05-03T21:54:13.928675Z","shell.execute_reply.started":"2022-05-03T21:54:13.923523Z","shell.execute_reply":"2022-05-03T21:54:13.927679Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Función para aplicar diferentes modelos de clasificación y guardar las métricas\ndef metricas_modelos_clasificacion(lista_clasificadores, X_train, y_train, X_test, y_test):\n    \n    # Inicializar el DataFrame resultado y las listas que lo compondrán\n    df_clasificadores = pd.DataFrame()\n    lista_clasificador = list()\n    lista_jaccard_index = list()\n    lista_accuracy = list()\n    lista_precision = list()\n    lista_sensibilidad = list()\n    lista_f1_score = list()\n    lista_confusion_matrix = list()\n    lista_tiempo = list()\n\n    # Por cada método de la lista de clasificadores\n    for clasificador in lista_clasificadores:\n        \n        print(str(clasificador))\n\n        # Momento de inicio de ejecución del modelo\n        inicio = time.time()\n\n        # Entrenar el método\n        clasificador.fit(X_train, y_train)\n\n        # Calcular la predicción\n        yhat = clasificador.predict(X_test)\n\n        # Momento de fin de ejecución del modelo\n        fin = time.time()\n        \n        tiempo = fin - inicio\n\n        # Calcular las métricas\n        jaccard_m = jaccard_score(y_test, yhat, average = \"macro\")\n        accuracy_m = accuracy_score(y_test, yhat)\n        precision_m = precision_score(y_test, yhat, average = \"macro\")\n        recall_m = recall_score(y_test, yhat, average = \"macro\")\n        f1_m = f1_score(y_test, yhat, average = \"macro\")\n        conf_matrix = confusion_matrix(y_test, yhat)\n\n        print(\"Jaccard Index:\", jaccard_m)\n        print(\"Accuracy:\"     , accuracy_m)\n        print(\"Precisión:\"    , precision_m)\n        print(\"Sensibilidad:\" , recall_m)\n        print(\"F1-score:\"     , f1_m)\n        print(\"Confusion Matrix:\\n\", conf_matrix)\n        print(f\"Tiempo de ejecución: {tiempo}\")\n        print(\"*\"*100)\n        \n        # Guardar el nombre del método de clasificación\n        lista_clasificador.append(str(clasificador))\n        # Guardar las métricas\n        lista_jaccard_index.append(jaccard_m)\n        lista_accuracy.append(accuracy_m)\n        lista_precision.append(precision_m)\n        lista_sensibilidad.append(recall_m)\n        lista_f1_score.append(f1_m)\n        lista_confusion_matrix.append(conf_matrix)\n        # Guardar el tiempo de ejecución\n        lista_tiempo.append(tiempo)\n    \n    # Guardar las listas en el DataFrame\n    df_clasificadores[\"metodo_clasificador\"] = lista_clasificador\n    df_clasificadores[\"jaccard_index\"] = lista_jaccard_index\n    df_clasificadores[\"accuracy\"] = lista_accuracy\n    df_clasificadores[\"precision\"] = lista_precision\n    df_clasificadores[\"sensibilidad\"] = lista_sensibilidad\n    df_clasificadores[\"f1_score\"] = lista_f1_score\n    df_clasificadores[\"confusion_matrix\"] = lista_confusion_matrix\n    df_clasificadores[\"tiempo_ejecucion\"] = lista_tiempo\n\n    return df_clasificadores","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:13.929988Z","iopub.execute_input":"2022-05-03T21:54:13.930214Z","iopub.status.idle":"2022-05-03T21:54:13.945763Z","shell.execute_reply.started":"2022-05-03T21:54:13.930187Z","shell.execute_reply":"2022-05-03T21:54:13.944484Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"lista_clasificadores = [KNeighborsClassifier(n_neighbors = 3),\n                        RadiusNeighborsClassifier(radius = 0.8,\n                                                  outlier_label = \"most_frequent\"),\n                        NearestCentroid(metric = \"euclidean\"),\n                        GaussianNB(),\n                        LogisticRegression(),\n                        DecisionTreeClassifier(),\n                        RandomForestClassifier()\n                       ]","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:13.947060Z","iopub.execute_input":"2022-05-03T21:54:13.947442Z","iopub.status.idle":"2022-05-03T21:54:13.962851Z","shell.execute_reply.started":"2022-05-03T21:54:13.947400Z","shell.execute_reply":"2022-05-03T21:54:13.962144Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"%%time\n\nmetricas_modelos_clasificacion(lista_clasificadores, X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:54:13.964082Z","iopub.execute_input":"2022-05-03T21:54:13.964295Z","iopub.status.idle":"2022-05-03T22:18:47.583395Z","shell.execute_reply.started":"2022-05-03T21:54:13.964269Z","shell.execute_reply":"2022-05-03T22:18:47.582381Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# El modelo más adecuado en base a las métricas es RandomForestClassifier","metadata":{"execution":{"iopub.status.busy":"2022-05-03T22:18:47.584791Z","iopub.execute_input":"2022-05-03T22:18:47.585047Z","iopub.status.idle":"2022-05-03T22:18:47.590746Z","shell.execute_reply.started":"2022-05-03T22:18:47.585014Z","shell.execute_reply":"2022-05-03T22:18:47.589636Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"############################################################################################\n# Seleccionar el mejor modelo y aplicar GridSearch() para encontrar los mejores parámetros #\n############################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-05-03T22:18:47.592070Z","iopub.execute_input":"2022-05-03T22:18:47.592304Z","iopub.status.idle":"2022-05-03T22:18:47.606689Z","shell.execute_reply.started":"2022-05-03T22:18:47.592269Z","shell.execute_reply":"2022-05-03T22:18:47.605915Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def aplicar_GridSearchCV(modelo, params, scorers, metric):\n    \n    model = modelo\n    \n    grid_solver = GridSearchCV(estimator  = model    , \n                           param_grid = params   , \n                           scoring    = scorers  ,\n                           cv         = 5        ,\n                           refit      = metric,\n                           n_jobs     = -1        )\n    model_result = grid_solver.fit(X_train, y_train)\n\n    print(model_result.cv_results_[\"mean_test_recall_macro\"].mean())\n    print(model_result.cv_results_[\"mean_test_f1_macro\"].mean())\n    print(model_result.cv_results_[\"mean_test_accuracy\"].mean())\n\n    print(\"*\"*100)\n\n    print(model_result.best_score_)\n    print(model_result.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T22:18:47.610551Z","iopub.execute_input":"2022-05-03T22:18:47.611137Z","iopub.status.idle":"2022-05-03T22:18:47.620342Z","shell.execute_reply.started":"2022-05-03T22:18:47.611100Z","shell.execute_reply":"2022-05-03T22:18:47.619592Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"modelo = RandomForestClassifier()\n\nparams = {\"n_estimators\"           : [100, 200, 300], # Numero de arboles\n          \"criterion\"              : [\"gini\", \"entropy\"], # Función para medir la calidad de una división/split\n          \"max_depth\"              : [3, 4, 5], # Profundidad máxima del árbol\n          \"max_features\"           : [2, 3], # Número de características a considerar en cada split\n          \"max_leaf_nodes\"         : [8], # Máximo número de nodos hoja del árbol\n          \"min_impurity_decrease\"  : [0.02, 0.3], # Un nodo se dividirá si esta división induce una disminución de la impureza mayor o igual a este valor.\n          \"min_samples_split\"      : [2, 5]} # Número mínimo de muestras requeridas para llegar a nodo hoja\n\nscorers = {\"f1_macro\", \"accuracy\", \"recall_macro\"}\n\nmetric = \"accuracy\"\n\naplicar_GridSearchCV(modelo, params, scorers, metric)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T22:18:47.621698Z","iopub.execute_input":"2022-05-03T22:18:47.622190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ejecución del resto de métodos de clasificación que requieren más tiempo","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nlista_clasificadores2 = [AdaBoostClassifier(),\n                         GradientBoostingClassifier(),\n                         SVC()]\n\n\nmetricas_modelos_clasificacion(lista_clasificadores2, X_train, y_train, X_test, y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}